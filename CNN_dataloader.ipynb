{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CHiFQDidXFp",
        "outputId": "1ecb5067-f955-43ff-b956-f29d762645b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TrainTweetDataset(Dataset):\n",
        "    def __init__(self, n_blocs, data_dir, device, transform=None, target_transform=None):\n",
        "        self.n_blocs = n_blocs\n",
        "        self.device = device\n",
        "        self.labels = {idx: torch.load(data_dir+f\"y_train_cnn_new_{idx}_full.pt\", self.device)\n",
        "                       for idx in range(n_blocs)}\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_blocs\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        train_data = torch.load(self.data_dir+f\"X_train_cnn_new_{idx}_full_3CH.pt\", self.device)\n",
        "        #train_data = train_data.view(train_data.shape[0], 3, 50, 20)\n",
        "        labels = self.labels[idx]\n",
        "        if self.transform:\n",
        "            train_data = self.transform(train_data)\n",
        "        if self.target_transform:\n",
        "            labels = self.target_transform(labels)\n",
        "        return train_data, labels\n",
        "\n",
        "class TestTweetDataset(Dataset):\n",
        "    def __init__(self, n_blocs, data_dir, device, transform=None, target_transform=None):\n",
        "        self.device = device\n",
        "        self.n_blocs = n_blocs\n",
        "        self.labels = {idx: torch.load(data_dir+f\"y_test_cnn_new_{idx}_full.pt\", self.device)\n",
        "                       for idx in range(n_blocs)}\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_blocs\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        test_data = torch.load(self.data_dir+f\"X_test_cnn_new_{idx}_full_3CH.pt\", self.device)\n",
        "        #test_data = test_data.view(test_data.shape[0], 3, 50, 20)\n",
        "        labels = self.labels[idx]\n",
        "        if self.transform:\n",
        "            test_data = self.transform(test_data)\n",
        "        if self.target_transform:\n",
        "            labels = self.target_transform(labels)\n",
        "        return test_data, labels\n"
      ],
      "metadata": {
        "id": "MZ_-ikz0ySVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(X_train, epochs, learning_rate, model, l, y_train):\n",
        "    batch_size = BATCH_SIZE\n",
        "    pred_train=[]\n",
        "    Nb_tweets=X_train.shape[0]\n",
        "    threshold = 0.5\n",
        "    # y_train = y_train.type(torch.LongTensor)\n",
        "    y_train[y_train == -1] = 1  # between 0 and 1 instead of -1 and 0\n",
        "    o=torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    model.train()\n",
        "    # initialize an empty dictionary\n",
        "    res = {'epoch': [], 'train_loss': []}\n",
        "    for e in range(epochs):\n",
        "        print(f\"Epoch {e+1}\\n-------------------------------\")\n",
        "        running_loss=0\n",
        "        permutation = torch.randperm(X_train.size()[0])\n",
        "        for i in range(0, X_train.size()[0], batch_size):\n",
        "            if i%10000 == 0:\n",
        "                print(f\"Tweet {i}\")\n",
        "            indices = permutation[i:i+batch_size]\n",
        "            batch_x, batch_y = X_train[indices], y_train[indices]\n",
        "            outputs = model(batch_x)\n",
        "            #binary_predictions = (outputs >= threshold).float()\n",
        "            pred_train.append(outputs)\n",
        "            o.zero_grad() # setting gradient to zeros, bc I don't wanna accumulate the grads of all layers\n",
        "            loss = l(outputs, batch_y)\n",
        "            loss.backward() # backward propagation\n",
        "            o.step() # update the gradient to new gradients\n",
        "            running_loss += loss.item()\n",
        "        running_loss=running_loss/batch_size\n",
        "        res['epoch'].append(e) # populate the dictionary of results\n",
        "        res['train_loss'].append(running_loss)\n",
        "    print(\"Done!\")\n",
        "    res = pd.DataFrame.from_dict(res) # translate the dictionary into a pandas dataframe\n",
        "    res.to_csv(\"./metrics_over_epochs_0{:.5f}.csv\".format(learning_rate), mode = 'w', index = False) # store the results into a *.csv file\n",
        "    return res['train_loss'], pred_train"
      ],
      "metadata": {
        "id": "1RKQTAsLlD31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================== CONSTANTS ===============================\n",
        "# Main directory path\n",
        "PREFIX = '/content/drive/MyDrive/Colab Notebooks/batches/small/'\n",
        "# Number of blocs of data\n",
        "N_BLOCS = 6\n",
        "# Batch size inside a bloc\n",
        "BATCH_SIZE = 500\n",
        "# Number of features, equivalent to the embedding size\n",
        "N_FEATURES = 20\n",
        "# Number of channels, equivalent to the number of different embedding used\n",
        "N_CHANNELS = 3\n",
        "# Truncated length of tweets\n",
        "LEN_TWEET = 50\n",
        "# ========================================================================="
      ],
      "metadata": {
        "id": "eMxul3Rd0-lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRfkYR1rdXFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7020ced0-c395-495e-9733-6d36930a932d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "device=cuda:0\n"
          ]
        }
      ],
      "source": [
        "def device_type():\n",
        "    if torch.cuda.is_available():\n",
        "        return 'cuda:0'\n",
        "    elif torch.backends.mps.is_available():\n",
        "        return 'mps'\n",
        "    else:\n",
        "        return 'cpu'\n",
        "device = torch.device(device_type())\n",
        "print(f\"device={device}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, hidden_size1, hidden_size2, kernel_size, output_size):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=input_size[0], out_channels=hidden_size, kernel_size=kernel_size, stride=N_FEATURES, padding=0)#(d - kernel_size + 1) / 1 = (10000 - 3 + 1) / 1 = 9999\n",
        "        output1=(input_size[1]-kernel_size+1)/(kernel_size/2)+1\n",
        "        #print(\"output1 after conv1\", output1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.pool_kernel_size = 3\n",
        "        self.pool_stride = 1\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=self.pool_kernel_size, stride=self.pool_stride)\n",
        "        output2=(output1-self.pool_kernel_size+1)/1\n",
        "        #print(\"output2 after pool1\", output2)\n",
        "\n",
        "        self.conv1d_kernel_size = 2\n",
        "        self.conv2 = nn.Conv1d(in_channels=hidden_size, out_channels=hidden_size1, kernel_size=self.conv1d_kernel_size, stride=1, padding=1)\n",
        "        output3=(output2-self.conv1d_kernel_size+2*1)/1+1\n",
        "        #print(\"output3, after conv2\", output3)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2_kernel_size = 2\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=self.pool2_kernel_size, stride=self.pool_stride)\n",
        "        self.output4=math.floor((output3-self.pool2_kernel_size+1)/self.pool_stride)\n",
        "        #print(\"output4 after pool2 = \", self.output4)\n",
        "        self.fc1 = nn.Linear(BATCH_SIZE*self.output4, hidden_size2)\n",
        "        self.fc_last = nn.Linear(2664, hidden_size2)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size2, output_size)\n",
        "\n",
        "\n",
        "        #self.softmax=nn.Softmax(dim= 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #print(x.shape)\n",
        "        if x.shape[0]!=BATCH_SIZE and x.shape[0]!=0:\n",
        "          x = x.view(x.shape[0], 3, -1)\n",
        "        else:\n",
        "          x = x.view(BATCH_SIZE,3,-1)#1,980\n",
        "\n",
        "        #print(f\"x.view(batch_size,3,-1) {x.shape}\")\n",
        "        x = self.conv1(x) #12,48\n",
        "        #print(f\"self.conv1(x) {x.shape}\")\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)#12,46\n",
        "        #print(f\"self.pool1(x) {x.shape}\")\n",
        "        x = self.conv2(x)#1,47\n",
        "        #print(f\"self.conv2(x) {x.shape}\")\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)#1,46\n",
        "        #print(f\"self.pool2(x) {x.shape}\")\n",
        "        x = x.view(x.size(0),-1)\n",
        "        #print(f\"x.view(x. {x.shape}\")\n",
        "\n",
        "        if x.shape[1]!=BATCH_SIZE*self.output4:\n",
        "          x = self.fc_last(x)\n",
        "          #print(\"x.shape boucle if =\", x.shape)\n",
        "        else:\n",
        "          x = self.fc1(x)#1,16\n",
        "          #print(f\"self.fc1(x) {x.shape}\")\n",
        "        #print(\"x.shape after fc1 =\", x.shape)\n",
        "        x = self.relu3(x)\n",
        "        #print(\"x.shape after relu =\", x.shape)\n",
        "        x = self.fc2(x)\n",
        "        #print(f\"self.fc2(x) {x.shape}\")\n",
        "\n",
        "        #x = self.softmax(x)\n",
        "        #x = self.sigmoid(x)\n",
        "        x = x.flatten()\n",
        "        #print(\"after flatten shape = \", x.shape)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fH5kImkErjkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_vs_lr(losses, learning_rates, filename):\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for i in range(len(learning_rate)):\n",
        "        plt.plot(np.arange(0,epochs,1), losses[i], label=f'Learning rate = {learning_rates[i]}')\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Error')\n",
        "    plt.title('Train Error')\n",
        "    plt.grid(True)\n",
        "    plt.legend(loc='upper right', title='train loop', fontsize='medium')\n",
        "    plt.savefig(filename)\n"
      ],
      "metadata": {
        "id": "nwTipGBR1vWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = TrainTweetDataset(6, PREFIX, device)\n",
        "test_ds = TestTweetDataset(6, PREFIX, device)\n",
        "train_dataloader = DataLoader(train_ds, batch_size=1, shuffle=True)\n",
        "test_dataloader = DataLoader(test_ds, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "DKD9HBTuwsxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL DEFINITION\n",
        "input_channels = N_CHANNELS\n",
        "nb_features = N_FEATURES\n",
        "len_tweet = LEN_TWEET\n",
        "\n",
        "hidden_size = 12\n",
        "hidden_size1 = BATCH_SIZE\n",
        "hidden_size2 = 16\n",
        "kernel_size = nb_features*2\n",
        "output_size = 1\n",
        "\n",
        "model = CNN(input_size=(input_channels,len_tweet*nb_features),\n",
        "        hidden_size=hidden_size,\n",
        "        hidden_size1=hidden_size1,\n",
        "        hidden_size2=hidden_size2,\n",
        "        kernel_size=kernel_size,\n",
        "        output_size=output_size)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "epochs=1 # ONLY ONE EPOCH FOR EXAMPLE\n",
        "learning_rate = np.logspace(-5,-1, 1)\n",
        "l= torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "ak0gQYID2KZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL TRAINING\n",
        "for idx_bloc in range(N_BLOCS-4): # ONLY FIRST 2 BLOCS FOR EXAMPLE\n",
        "    print(f\"Training bloc {idx_bloc}. Loading data...\")\n",
        "    X_train, y_train = next(iter(train_dataloader))\n",
        "    X_train = X_train.squeeze()\n",
        "    y_train = y_train.squeeze()\n",
        "    X_train = X_train.flatten(2)\n",
        "    losses = []\n",
        "    print(\"Done loading data, Training...\")\n",
        "    for lr in learning_rate:\n",
        "        loss = train_loop(X_train, epochs, lr, model, l, y_train)\n",
        "        losses.append(loss)\n",
        "    print(\"Done training.\")\n",
        "    del X_train, y_train\n",
        "    #plot_loss_vs_lr(losses, learning_rate, f'loss_vs_lr_bloc_{idx_bloc}.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzCrsDG93Eeh",
        "outputId": "d043bfd7-62a9-4342-db3a-b70eb0f1bc39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training bloc 0. Loading data...\n",
            "Done loading data, Training...\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Tweet 0\n",
            "Tweet 10000\n",
            "Tweet 20000\n",
            "Tweet 30000\n",
            "Tweet 40000\n",
            "Tweet 50000\n",
            "Tweet 60000\n",
            "Tweet 70000\n",
            "Tweet 80000\n",
            "Tweet 90000\n",
            "Tweet 100000\n",
            "Tweet 110000\n",
            "Tweet 120000\n",
            "Tweet 130000\n",
            "Tweet 140000\n",
            "Tweet 150000\n",
            "Tweet 160000\n",
            "Tweet 170000\n",
            "Tweet 180000\n",
            "Tweet 190000\n",
            "Tweet 200000\n",
            "Tweet 210000\n",
            "Tweet 220000\n",
            "Tweet 230000\n",
            "Tweet 240000\n",
            "Tweet 250000\n",
            "Tweet 260000\n",
            "Tweet 270000\n",
            "Tweet 280000\n",
            "Tweet 290000\n",
            "Done!\n",
            "Done training.\n",
            "Training bloc 1. Loading data...\n",
            "Done loading data, Training...\n",
            "Epoch 1\n",
            "-------------------------------\n",
            "Tweet 0\n",
            "Tweet 10000\n",
            "Tweet 20000\n",
            "Tweet 30000\n",
            "Tweet 40000\n",
            "Tweet 50000\n",
            "Tweet 60000\n",
            "Tweet 70000\n",
            "Tweet 80000\n",
            "Tweet 90000\n",
            "Tweet 100000\n",
            "Tweet 110000\n",
            "Tweet 120000\n",
            "Tweet 130000\n",
            "Tweet 140000\n",
            "Tweet 150000\n",
            "Tweet 160000\n",
            "Tweet 170000\n",
            "Tweet 180000\n",
            "Tweet 190000\n",
            "Tweet 200000\n",
            "Tweet 210000\n",
            "Tweet 220000\n",
            "Tweet 230000\n",
            "Tweet 240000\n",
            "Tweet 250000\n",
            "Tweet 260000\n",
            "Tweet 270000\n",
            "Tweet 280000\n",
            "Tweet 290000\n",
            "Done!\n",
            "Done training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "losses"
      ],
      "metadata": {
        "id": "yNvmMQkEPjhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_vs_lr(losses, learning_rate, \"test.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 913
        },
        "id": "2P4ptjp-PWA3",
        "outputId": "6b136de2-4268-4044-a5da-f42a2842609a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py:65: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ary = asanyarray(ary)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-36cff48b7f85>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_loss_vs_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-9b4c5f9b9dff>\u001b[0m in \u001b[0;36mplot_loss_vs_lr\u001b[0;34m(losses, learning_rates, filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'Learning rate = {learning_rates[i]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2810\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2811\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2812\u001b[0;31m     return gca().plot(\n\u001b[0m\u001b[1;32m   2813\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2814\u001b[0m         **({\"data\": data} if data is not None else {}), **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m         \"\"\"\n\u001b[1;32m   1687\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1689\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             yield from self._plot_args(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 this, kwargs, ambiguous_fmt_datakey=ambiguous_fmt_datakey)\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    505\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (2,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop(X_test,y_test, l, model):\n",
        "    #y_test=y_test[:,0]*(-1)\n",
        "    pred_test=[]\n",
        "    batch_size = BATCH_SIZE\n",
        "    test_loss=0\n",
        "    model.eval()\n",
        "    threshold = 0.5\n",
        "    with torch.no_grad():\n",
        "        # loop over all test input-output pairs\n",
        "        permutation = torch.randperm(X_test.size()[0])\n",
        "        for i in range(0, X_test.size()[0], batch_size):\n",
        "            if i%1000 == 0:\n",
        "                print(f\"Tweet {i}\")\n",
        "            indices = permutation[i:i+batch_size]\n",
        "            batch_x, batch_y = X_test[indices], y_test[indices]\n",
        "            outputs = model(batch_x)\n",
        "            #pred_test_np = torch.cat(outputs).detach().numpy()\n",
        "            #binary_predictions = (pred_test_np > threshold).astype(int)\n",
        "            pred_test.append(outputs)\n",
        "            #print(\"outputs\",outputs.shape)\n",
        "            #print(\"batchy\",batch_y)\n",
        "            loss = l(binary_predicions, batch_y)\n",
        "            test_loss += loss.item()\n",
        "        test_loss=test_loss/batch_size\n",
        "    return test_loss, pred_test"
      ],
      "metadata": {
        "id": "k_s-vE8X-756"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, y_pred1= test_loop(X_test, y_test, l, model)\n",
        "print(\"test_loss\", test_loss)\n",
        "#print(\"y_pred1\", y_pred1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qu7qLQgSwtm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_loop_final(X_test, model):\n",
        "    pred_test=[]\n",
        "    batch_size = BATCH_SIZE\n",
        "    test_loss=0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      # loop over all test input-output pairs\n",
        "        permutation = torch.randperm(X_test.size()[0])\n",
        "        for i in range(0, X_train.size()[0], batch_size):\n",
        "            if i%1000 == 0:\n",
        "                print(f\"Tweet {i}\")\n",
        "            indices = permutation[i:i+batch_size]\n",
        "            batch_x = X_test[indices]\n",
        "            outputs = model(batch_x)\n",
        "            pred_test.append(outputs)\n",
        "            #print(\"outputs\",outputs.shape)\n",
        "            #print(\"batchy\",batch_y)\n",
        "\n",
        "    return pred_test"
      ],
      "metadata": {
        "id": "S8X-b4nSDjuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_final =  test_loop_final(X_T, model)"
      ],
      "metadata": {
        "id": "UXiVuB_oDebk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Mt6mARIuDize"
      }
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  }
}