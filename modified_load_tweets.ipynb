{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9UXXBJoAWa1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e02bd365-1dfb-4729-c742-7ff093b10b7b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gWaztWJ_VOSX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LPgw53N-VOSZ"
      },
      "outputs": [],
      "source": [
        "# lire donn√©es\n",
        "\n",
        "PREFIX = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "\n",
        "EMBEDDINGS = PREFIX+\"embeddings.txt\"\n",
        "VOCAB = PREFIX+\"vocab.txt\"\n",
        "\n",
        "POS_TWEETS = PREFIX+\"twitter-datasets/train_pos.txt\"\n",
        "NEG_TWEETS = PREFIX+\"twitter-datasets/train_neg.txt\"\n",
        "TEST_DATA = PREFIX+\"twitter-datasets/test_data.txt\"\n",
        "\n",
        "# parse embeddings\n",
        "vecs = {}\n",
        "with open(EMBEDDINGS, \"r\") as f:\n",
        "    for line in f:\n",
        "        pline = line.rstrip().split(' ')\n",
        "        word = pline[0]\n",
        "        vecs[word] = np.array([float(x) for x in pline[1:]])\n",
        "\n",
        "# parse vocabulary and build an index\n",
        "with open(VOCAB, \"r\") as f:\n",
        "    vocab = {x.rstrip().split(' ')[0]: i for i,x in enumerate(f)}\n",
        "\n",
        "embeddings = np.zeros((len(vocab), len(vecs[list(vecs.keys())[0]])))\n",
        "for w, v in vecs.items():\n",
        "    if w == \"<unk>\":\n",
        "        continue\n",
        "    embeddings[vocab[w], :] = v\n",
        "\n",
        "with open(NEG_TWEETS, \"r\") as f:\n",
        "    n_tweets = [line.rstrip().split() for line in f]\n",
        "with open(POS_TWEETS, \"r\") as f:\n",
        "    p_tweets = [line.rstrip().split() for line in f]\n",
        "\n",
        "# Stack the two lists together (will be used to see max_length of tweet)\n",
        "combined_tweets = n_tweets + p_tweets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5F11ICqxVOSb"
      },
      "outputs": [],
      "source": [
        "testing_tweets = []\n",
        "testing_tweets_ids = []\n",
        "with open(TEST_DATA, \"r\") as f:\n",
        "    for line in f:\n",
        "        parsed_line = line.rstrip().split(',')\n",
        "        testing_tweets.append(','.join(parsed_line[1:]).split())\n",
        "        testing_tweets_ids.append(int(parsed_line[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert a tweet to an embedding of shape (max_length,) which is the length of maximal tweet, so added padding\n",
        "series_train=[]\n",
        "series_test=[]\n",
        "length_list=[]\n",
        "def modified_load_tweets(tweets_list, series, max_tweet_length, label=None ):\n",
        "    print(\"Loading tweets...\")\n",
        "    i = 0\n",
        "    tot = len(tweets_list)\n",
        "\n",
        "    vocab_keys = set(vocab.keys())\n",
        "\n",
        "    for tweet in tweets_list:\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"{i}/{tot} ({int(i/tot*100)} %)\")\n",
        "\n",
        "\n",
        "       # Filter out words not in the vocabulary\n",
        "        tweet_filtered = [word for word in tweet if word in vocab_keys]\n",
        "\n",
        "        # Create a tensor directly without using list comprehensions\n",
        "\n",
        "        embeddings_list_torch = torch.FloatTensor(np.array([embeddings[vocab[word]] for word in tweet_filtered]))\n",
        "\n",
        "        length_tweet=len(tweet_filtered)\n",
        "        length_list.append(length_tweet)\n",
        "\n",
        "        diff_length=max_tweet_length - length_tweet\n",
        "\n",
        "        if length_tweet == 0:\n",
        "            tweet_embeddings = torch.zeros((max_tweet_length, len(vecs[list(vecs.keys())[0]])))\n",
        "        else:\n",
        "           tweet_mean = torch.mean(embeddings_list_torch, axis=0)\n",
        "           tweet_embeddings = torch.ones((max_tweet_length, len(vecs[list(vecs.keys())[0]])))*tweet_mean # to have all tweets of shape (#tweets, max_tweet_len, 20)\n",
        "           middle = diff_length//2\n",
        "           if (diff_length%2==0):\n",
        "               tweet_embeddings[middle:max_tweet_length-middle,:] = embeddings_list_torch #putting them in the middle to do some kind of padding\n",
        "           else:\n",
        "               tweet_embeddings[middle:(max_tweet_length-(middle+1)),:] = embeddings_list_torch\n",
        "        if label is not None:\n",
        "            tweet_embeddings = torch.vstack((tweet_embeddings, label*torch.ones(20,)))\n",
        "        series.append(tweet_embeddings)\n",
        "        i += 1\n",
        "\n",
        "    return series"
      ],
      "metadata": {
        "id": "WRwp2If1luDP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Nbr_d4vQVOSd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "7e68bdf7-6a65-4d9b-940b-a4a93a89eff5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tweets...\n",
            "0/100000 (0 %)\n",
            "1000/100000 (1 %)\n",
            "2000/100000 (2 %)\n",
            "3000/100000 (3 %)\n",
            "4000/100000 (4 %)\n",
            "5000/100000 (5 %)\n",
            "6000/100000 (6 %)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6fa74c8aba99>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# add both negative and positive tweets, will be shuffled later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mseries_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified_load_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mseries_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified_load_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-717a9d5bacdf>\u001b[0m in \u001b[0;36mmodified_load_tweets\u001b[0;34m(tweets_list, series, max_tweet_length, label)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m            \u001b[0mtweet_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_list_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m            \u001b[0mtweet_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_tweet_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtweet_mean\u001b[0m \u001b[0;31m# to have all tweets of shape (#tweets, max_tweet_len, 20)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m            \u001b[0mmiddle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiff_length\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdiff_length\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "max_length_train = max(len(tweet) for tweet in combined_tweets)\n",
        "max_length_test = max(len(tweet) for tweet in testing_tweets)\n",
        "max_tot=max(max_length_train,max_length_test)\n",
        "\n",
        "\n",
        "\n",
        "# add both negative and positive tweets, will be shuffled later\n",
        "series_train = modified_load_tweets(p_tweets, series_train, max_tot, 1)\n",
        "series_train = modified_load_tweets(n_tweets, series_train, max_tot, -1)\n",
        "\n",
        "# no label since this is the prediction set\n",
        "series_test = modified_load_tweets(testing_tweets, series_test, max_tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "8hPzK1TrVOSe"
      },
      "outputs": [],
      "source": [
        "\n",
        "#use torch to represent data\n",
        "torch_series_train = torch.stack(series_train)\n",
        "torch_series_test = torch.stack(series_test)\n",
        "X = torch_series_train[:,:-1]\n",
        "y = torch_series_train[:,-1]\n",
        "RANDOM_SEED = 1234\n",
        "\n",
        "X_flattened = X.view(X.size(0), -1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED)\n",
        "X_train = X_train.view(X_train.size(0), max_tot, 20)\n",
        "X_test = X_test.view(X_test.size(0), max_tot, 20)\n",
        "torch.save(X_train, PREFIX+'X_train_cnn_new.pt')\n",
        "torch.save(X_test, PREFIX+'X_test_cnn_new.pt')\n",
        "torch.save(y_train, PREFIX+'y_train_cnn_new.pt')\n",
        "torch.save(y_test, PREFIX+'y_test_cnn_new.pt')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koOctk7UVOSe"
      },
      "outputs": [],
      "source": []
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  }
}