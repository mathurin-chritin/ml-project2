{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9UXXBJoAWa1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05725da6-aa77-4294-af90-2e8cfe9d2fed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gWaztWJ_VOSX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import math\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LPgw53N-VOSZ"
      },
      "outputs": [],
      "source": [
        "# lire donn√©es\n",
        "\n",
        "PREFIX = \"/content/drive/MyDrive/Colab Notebooks/\"\n",
        "\n",
        "EMBEDDINGS = PREFIX+\"embeddings.txt\"\n",
        "VOCAB = PREFIX+\"vocab.txt\"\n",
        "\n",
        "POS_TWEETS = PREFIX+\"twitter-datasets/train_pos.txt\"\n",
        "NEG_TWEETS = PREFIX+\"twitter-datasets/train_neg.txt\"\n",
        "TEST_DATA = PREFIX+\"twitter-datasets/test_data.txt\"\n",
        "\n",
        "# parse embeddings\n",
        "vecs = {}\n",
        "with open(EMBEDDINGS, \"r\") as f:\n",
        "    for line in f:\n",
        "        pline = line.rstrip().split(' ')\n",
        "        word = pline[0]\n",
        "        vecs[word] = np.array([float(x) for x in pline[1:]])\n",
        "\n",
        "# parse vocabulary and build an index\n",
        "with open(VOCAB, \"r\") as f:\n",
        "    vocab = {x.rstrip().split(' ')[0]: i for i,x in enumerate(f)}\n",
        "\n",
        "embeddings = np.zeros((len(vocab), len(vecs[list(vecs.keys())[0]])))\n",
        "for w, v in vecs.items():\n",
        "    if w == \"<unk>\":\n",
        "        continue\n",
        "    embeddings[vocab[w], :] = v\n",
        "\n",
        "with open(NEG_TWEETS, \"r\") as f:\n",
        "    n_tweets = [line.rstrip().split() for line in f]\n",
        "with open(POS_TWEETS, \"r\") as f:\n",
        "    p_tweets = [line.rstrip().split() for line in f]\n",
        "\n",
        "# Stack the two lists together (will be used to see max_length of tweet)\n",
        "combined_tweets = n_tweets + p_tweets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5F11ICqxVOSb"
      },
      "outputs": [],
      "source": [
        "testing_tweets = []\n",
        "testing_tweets_ids = []\n",
        "with open(TEST_DATA, \"r\") as f:\n",
        "    for line in f:\n",
        "        parsed_line = line.rstrip().split(',')\n",
        "        testing_tweets.append(','.join(parsed_line[1:]).split())\n",
        "        testing_tweets_ids.append(int(parsed_line[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert a tweet to an embedding of shape (max_length,) which is the length of maximal tweet, so added padding\n",
        "\n",
        "def modified_load_tweets(tweets_list, series, max_tweet_length, label=None ):\n",
        "    print(\"Loading tweets...\")\n",
        "    i = 0\n",
        "    tot = len(tweets_list)\n",
        "\n",
        "    vocab_keys = set(vocab.keys())\n",
        "\n",
        "    for tweet in tweets_list:\n",
        "        if i % 1000 == 0:\n",
        "            print(f\"{i}/{tot} ({int(i/tot*100)} %)\")\n",
        "\n",
        "\n",
        "       # Filter out words not in the vocabulary\n",
        "        tweet_filtered = [word for word in tweet if word in vocab_keys]\n",
        "\n",
        "        # Create a tensor directly without using list comprehensions\n",
        "\n",
        "        embeddings_list_torch = torch.FloatTensor(np.array([embeddings[vocab[word]] for word in tweet_filtered]))\n",
        "\n",
        "        length_tweet=len(tweet_filtered)\n",
        "        length_list.append(length_tweet)\n",
        "\n",
        "        diff_length=max_tweet_length - length_tweet\n",
        "\n",
        "        if length_tweet == 0:\n",
        "            tweet_embeddings = torch.zeros((max_tweet_length, len(vecs[list(vecs.keys())[0]])))\n",
        "        else:\n",
        "           tweet_mean = torch.mean(embeddings_list_torch, axis=0)\n",
        "           tweet_embeddings = torch.ones((max_tweet_length, len(vecs[list(vecs.keys())[0]])))*tweet_mean # to have all tweets of shape (#tweets, max_tweet_len, 20)\n",
        "           middle = diff_length//2\n",
        "           if (diff_length%2==0):\n",
        "               tweet_embeddings[middle:max_tweet_length-middle,:] = embeddings_list_torch #putting them in the middle to do some kind of padding\n",
        "           else:\n",
        "               tweet_embeddings[middle:(max_tweet_length-(middle+1)),:] = embeddings_list_torch\n",
        "        if label is not None:\n",
        "            tweet_embeddings = torch.vstack((tweet_embeddings, label*torch.ones(20,)))\n",
        "\n",
        "        series[i] = tweet_embeddings\n",
        "        i += 1\n",
        "\n",
        "    return series"
      ],
      "metadata": {
        "id": "WRwp2If1luDP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save(torch_series_train, torch_series_test):\n",
        "    SUFFIX = '.pt'\n",
        "\n",
        "    X = torch_series_train[:,:-1]\n",
        "    y = torch_series_train[:,-1]\n",
        "    RANDOM_SEED = 1234\n",
        "\n",
        "    X_flattened = X.view(X.size(0), -1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=RANDOM_SEED)\n",
        "    X_train = X_train.view(X_train.size(0), max_tot, 20)\n",
        "    X_test = X_test.view(X_test.size(0), max_tot, 20)\n",
        "    torch.save(X_train, PREFIX+'X_train_cnn_new'+SUFFIX)\n",
        "    torch.save(X_test, PREFIX+'X_test_cnn_new'+SUFFIX)\n",
        "    torch.save(y_train, PREFIX+'y_train_cnn_new'+SUFFIX)\n",
        "    torch.save(y_test, PREFIX+'y_test_cnn_new'+SUFFIX)\n",
        "    torch.save(torch_series_test, PREFIX+'X_T.pt')\n"
      ],
      "metadata": {
        "id": "6wPBYMniukDC"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Nbr_d4vQVOSd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "74e452a0-765a-4dea-fd40-ff577899fd29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tweets...\n",
            "0/100000 (0 %)\n",
            "1000/100000 (1 %)\n",
            "2000/100000 (2 %)\n",
            "3000/100000 (3 %)\n",
            "4000/100000 (4 %)\n",
            "5000/100000 (5 %)\n",
            "6000/100000 (6 %)\n",
            "7000/100000 (7 %)\n",
            "8000/100000 (8 %)\n",
            "9000/100000 (9 %)\n",
            "10000/100000 (10 %)\n",
            "11000/100000 (11 %)\n",
            "12000/100000 (12 %)\n",
            "13000/100000 (13 %)\n",
            "14000/100000 (14 %)\n",
            "15000/100000 (15 %)\n",
            "16000/100000 (16 %)\n",
            "17000/100000 (17 %)\n",
            "18000/100000 (18 %)\n",
            "19000/100000 (19 %)\n",
            "20000/100000 (20 %)\n",
            "21000/100000 (21 %)\n",
            "22000/100000 (22 %)\n",
            "23000/100000 (23 %)\n",
            "24000/100000 (24 %)\n",
            "25000/100000 (25 %)\n",
            "26000/100000 (26 %)\n",
            "27000/100000 (27 %)\n",
            "28000/100000 (28 %)\n",
            "29000/100000 (28 %)\n",
            "30000/100000 (30 %)\n",
            "31000/100000 (31 %)\n",
            "32000/100000 (32 %)\n",
            "33000/100000 (33 %)\n",
            "34000/100000 (34 %)\n",
            "35000/100000 (35 %)\n",
            "36000/100000 (36 %)\n",
            "37000/100000 (37 %)\n",
            "38000/100000 (38 %)\n",
            "39000/100000 (39 %)\n",
            "40000/100000 (40 %)\n",
            "41000/100000 (41 %)\n",
            "42000/100000 (42 %)\n",
            "43000/100000 (43 %)\n",
            "44000/100000 (44 %)\n",
            "45000/100000 (45 %)\n",
            "46000/100000 (46 %)\n",
            "47000/100000 (47 %)\n",
            "48000/100000 (48 %)\n",
            "49000/100000 (49 %)\n",
            "50000/100000 (50 %)\n",
            "51000/100000 (51 %)\n",
            "52000/100000 (52 %)\n",
            "53000/100000 (53 %)\n",
            "54000/100000 (54 %)\n",
            "55000/100000 (55 %)\n",
            "56000/100000 (56 %)\n",
            "57000/100000 (56 %)\n",
            "58000/100000 (57 %)\n",
            "59000/100000 (59 %)\n",
            "60000/100000 (60 %)\n",
            "61000/100000 (61 %)\n",
            "62000/100000 (62 %)\n",
            "63000/100000 (63 %)\n",
            "64000/100000 (64 %)\n",
            "65000/100000 (65 %)\n",
            "66000/100000 (66 %)\n",
            "67000/100000 (67 %)\n",
            "68000/100000 (68 %)\n",
            "69000/100000 (69 %)\n",
            "70000/100000 (70 %)\n",
            "71000/100000 (71 %)\n",
            "72000/100000 (72 %)\n",
            "73000/100000 (73 %)\n",
            "74000/100000 (74 %)\n",
            "75000/100000 (75 %)\n",
            "76000/100000 (76 %)\n",
            "77000/100000 (77 %)\n",
            "78000/100000 (78 %)\n",
            "79000/100000 (79 %)\n",
            "80000/100000 (80 %)\n",
            "81000/100000 (81 %)\n",
            "82000/100000 (82 %)\n",
            "83000/100000 (83 %)\n",
            "84000/100000 (84 %)\n",
            "85000/100000 (85 %)\n",
            "86000/100000 (86 %)\n",
            "87000/100000 (87 %)\n",
            "88000/100000 (88 %)\n",
            "89000/100000 (89 %)\n",
            "90000/100000 (90 %)\n",
            "91000/100000 (91 %)\n",
            "92000/100000 (92 %)\n",
            "93000/100000 (93 %)\n",
            "94000/100000 (94 %)\n",
            "95000/100000 (95 %)\n",
            "96000/100000 (96 %)\n",
            "97000/100000 (97 %)\n",
            "98000/100000 (98 %)\n",
            "99000/100000 (99 %)\n",
            "Loading tweets...\n",
            "0/100000 (0 %)\n",
            "1000/100000 (1 %)\n",
            "2000/100000 (2 %)\n",
            "3000/100000 (3 %)\n",
            "4000/100000 (4 %)\n",
            "5000/100000 (5 %)\n",
            "6000/100000 (6 %)\n",
            "7000/100000 (7 %)\n",
            "8000/100000 (8 %)\n",
            "9000/100000 (9 %)\n",
            "10000/100000 (10 %)\n",
            "11000/100000 (11 %)\n",
            "12000/100000 (12 %)\n",
            "13000/100000 (13 %)\n",
            "14000/100000 (14 %)\n",
            "15000/100000 (15 %)\n",
            "16000/100000 (16 %)\n",
            "17000/100000 (17 %)\n",
            "18000/100000 (18 %)\n",
            "19000/100000 (19 %)\n",
            "20000/100000 (20 %)\n",
            "21000/100000 (21 %)\n",
            "22000/100000 (22 %)\n",
            "23000/100000 (23 %)\n",
            "24000/100000 (24 %)\n",
            "25000/100000 (25 %)\n",
            "26000/100000 (26 %)\n",
            "27000/100000 (27 %)\n",
            "28000/100000 (28 %)\n",
            "29000/100000 (28 %)\n",
            "30000/100000 (30 %)\n",
            "31000/100000 (31 %)\n",
            "32000/100000 (32 %)\n",
            "33000/100000 (33 %)\n",
            "34000/100000 (34 %)\n",
            "35000/100000 (35 %)\n",
            "36000/100000 (36 %)\n",
            "37000/100000 (37 %)\n",
            "38000/100000 (38 %)\n",
            "39000/100000 (39 %)\n",
            "40000/100000 (40 %)\n",
            "41000/100000 (41 %)\n",
            "42000/100000 (42 %)\n",
            "43000/100000 (43 %)\n",
            "44000/100000 (44 %)\n",
            "45000/100000 (45 %)\n",
            "46000/100000 (46 %)\n",
            "47000/100000 (47 %)\n",
            "48000/100000 (48 %)\n",
            "49000/100000 (49 %)\n",
            "50000/100000 (50 %)\n",
            "51000/100000 (51 %)\n",
            "52000/100000 (52 %)\n",
            "53000/100000 (53 %)\n",
            "54000/100000 (54 %)\n",
            "55000/100000 (55 %)\n",
            "56000/100000 (56 %)\n",
            "57000/100000 (56 %)\n",
            "58000/100000 (57 %)\n",
            "59000/100000 (59 %)\n",
            "60000/100000 (60 %)\n",
            "61000/100000 (61 %)\n",
            "62000/100000 (62 %)\n",
            "63000/100000 (63 %)\n",
            "64000/100000 (64 %)\n",
            "65000/100000 (65 %)\n",
            "66000/100000 (66 %)\n",
            "67000/100000 (67 %)\n",
            "68000/100000 (68 %)\n",
            "69000/100000 (69 %)\n",
            "70000/100000 (70 %)\n",
            "71000/100000 (71 %)\n",
            "72000/100000 (72 %)\n",
            "73000/100000 (73 %)\n",
            "74000/100000 (74 %)\n",
            "75000/100000 (75 %)\n",
            "76000/100000 (76 %)\n",
            "77000/100000 (77 %)\n",
            "78000/100000 (78 %)\n",
            "79000/100000 (79 %)\n",
            "80000/100000 (80 %)\n",
            "81000/100000 (81 %)\n",
            "82000/100000 (82 %)\n",
            "83000/100000 (83 %)\n",
            "84000/100000 (84 %)\n",
            "85000/100000 (85 %)\n",
            "86000/100000 (86 %)\n",
            "87000/100000 (87 %)\n",
            "88000/100000 (88 %)\n",
            "89000/100000 (89 %)\n",
            "90000/100000 (90 %)\n",
            "91000/100000 (91 %)\n",
            "92000/100000 (92 %)\n",
            "93000/100000 (93 %)\n",
            "94000/100000 (94 %)\n",
            "95000/100000 (95 %)\n",
            "96000/100000 (96 %)\n",
            "97000/100000 (97 %)\n",
            "98000/100000 (98 %)\n",
            "99000/100000 (99 %)\n",
            "Loading tweets...\n",
            "0/10000 (0 %)\n",
            "1000/10000 (10 %)\n",
            "2000/10000 (20 %)\n",
            "3000/10000 (30 %)\n",
            "4000/10000 (40 %)\n",
            "5000/10000 (50 %)\n",
            "6000/10000 (60 %)\n",
            "7000/10000 (70 %)\n",
            "8000/10000 (80 %)\n",
            "9000/10000 (90 %)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-5b5a37d8c392>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mseries_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodified_load_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtesting_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: save() missing 1 required positional argument: 'series_test'"
          ]
        }
      ],
      "source": [
        "max_length_train = max(len(tweet) for tweet in combined_tweets)\n",
        "max_length_test = max(len(tweet) for tweet in testing_tweets)\n",
        "max_tot=max(max_length_train, max_length_test)\n",
        "\n",
        "series_train = torch.zeros((len(combined_tweets), max_tot+1, 20)) # +1 for label\n",
        "series_test = torch.zeros((len(testing_tweets), max_tot, 20))\n",
        "length_list = []\n",
        "# add both negative and positive tweets, will be shuffled later\n",
        "series_train = modified_load_tweets(p_tweets, series_train, max_tot, 1)\n",
        "series_train = modified_load_tweets(n_tweets, series_train, max_tot, -1)\n",
        "\n",
        "# no label since this is the prediction set\n",
        "series_test = modified_load_tweets(testing_tweets, series_test, max_tot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "koOctk7UVOSe"
      },
      "outputs": [],
      "source": [
        "save(series_train, series_test)"
      ]
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  }
}